---
title: 如何保持 MySQL  和 Redis 中数据的一致性
date: 2023-04-10 14:51:10
permalink: /pages/521984/
---

Redis 的 QPS 可以支撑到10万

MySQL 的 QPS 可以支撑到2K



Redis 和 源数据的一致性问题

使用 Spring 开发系统 =》 控制缓存的读取和更新，在一般公司是没什么问题的。对于高并发的大厂，这么设计肯定不够。



1. Spring 的注解是怎么使用的，它是怎么控制缓存更新的？

2. 使用 api 操作 Redis 的一些错误方式，以及由其带来的一致性问题
3. cache aside pattern，解决多数一致性问题，"延迟双删" 和 "闪电缓存"
4. JVM 停顿造成的不一致性，并看下怎么解决它
5. “读操作互斥”和“集中更新”

Java 的 Redis 客户端常见的有三种：

1. jedis
2. redisson
3. lettuce

Spring 缓存包，spring-cache  => AOP  => Cache

```maven
<dependency>
	<groupId>org.springframework.boot</groupId>
	<artifactId>spring-boot-starter-cache</artifactId>
</dependency>
```

- 启动类加入 `@EnableCaching` 注解

- 使用 `CacheManager` 初始化要使用的缓存框架

- 使用 `CacheConfig` 注解注入要使用的资源

- `@Cacheable` 表示如果缓存系统里没有这个数值，就将方法返回值缓存起来
- `@CachePut` 表示每次执行该方法，都把返回值缓存起来
- `@CacheEvict` 表示执行方法的时候，清除某些缓存值



### 一致性问题是如何产生的？

Redis 是当做缓存时候，不适合做数据库。Redis的操作速度比数据库的操作速度快的多。

一致性，简单说就是“数据库里的数据”与“Redis中的数据”不一致。



双更新模式：操作不合理，导致数据一致性问题。

```java
public void putValue(key, value) {
  putToRedis(key, value);
  putToDB(key, value); // 操作失败了
}
```

先刷新缓存，再更新数据库，但是在过程中，更新数据库可能会失败，发生了回滚，最后缓存里面的数据和数据库里面的数据就不一样了。



改成：

```java
public void putValue(key, value) {
  putToRedis(key, value);
  putToDB(key, value); // 操作失败了
}
```

先更新数据库，再更新缓存，仍然有问题，当两个请求的时序发生了错乱，就会发生缓存不一致的情况。

![](/img/10.backend/image-20220207103217828.png)

当更新a的值为1，操作B更新a的值为2，由于数据库和Redis的操作并不是原子的，它们的执行时长也不是可控的

当两个的请求时序发生了缓存，就会发生缓存不一致的情况。双更新的主要问题，并不是体现在数据的一致性上，而是业务操作的合理性上。采用“更新”的方式，计算代码就分散在项目的多个地方。

> 余额 = 钱包里的值 + 基金里的值



“缓存更新” 改成 “删除”

因为每次读取的时候，判断Redis 里面没有值，就会重新读取数据库。现在的问题是，先删除缓存还是后删除缓存，正确的方式应该是后删除缓存。



如果先删除缓存：

```java
public void putValue(key, value) {
  deleteFromRedis(key);
  putToDB(key, value);
}
```

如果操作b删除了某个k的值，这时候正好有另一个请求a到来，那么他就会击穿到数据库，读取到旧的值。



如果后删除缓存：

```java
public void putValue(key, value) {
  putToDB(key, value);
  deleteFromRedis(key);
}
```

则可以保证每次读取到的值都是最新的，从数据库拿到的都是最新的，这就是我们通常说的Cache-Aside Pattern。



Cache-Aside Pattern

数据的读取过程：

1. 每次读取数据，都从cache里读
    - 如果读取不到cache的数据时，则从 db 里面捞一份，操作 cache miss
    - 如果读到了，则直接返回，称作 cache hit

2. 将读取到的数据塞入到缓存中，下次读取时，就可以直接命中

数据写的过程：

1. 将变更写入到数据库中
2. 删除缓存里对应的数据

Spring Cache 实现了上述模式。



在高并发场景下，Cache-Aside Pattern 存在问题：

![](/img/10.backend/image-20220207105038577.png)

在高并发多实例的场景中很常见。

```java
public void process(key, value) {
  N:putToDB(key:1);
  N:deleteFromRedis(key);
  
  A:getFromRedis(key);
  A:getFromDB(key)=1;
  B:putToDB(key:2);
  N:deleteFromRedis(key);
  A:putToRedis(key:1);
}
```

一般情况下，读取操作都是比写入操作快的，但是我们要考虑两种极端情况：

1. 读取操作A，发生在更新操作B的尾部。
2. 操作A的Redis的操作时长，耗费了非常多的时间（比如：节点正好发生了STW）

读操作A的结束时间超过了操作B的删除动作，实际上你也无法控制他们的执行顺序。只要发生这种情况，大概率数据库和Redis的值不一致。

通常一般公司不去处理这种情况，主要是它发生的条件非常苛刻：要求在一系列“并发写”的同时，还有“并发读”的参与。本质问题是，删除操作发生在更新操作之前。



是否有一种机制能够确保，删除操作一定被执行就可以解决问题。至少可以缩小数据不一致的时间窗口。

- 延时双删

```java
public void putValue(key, value) {
  putToDB(key, value);
  deleteFromRedis(key);
  
  ... deleteFromRedis(key, afterSec)；
}
```

删除动作再执行一次，比如5秒之后。比如，放在内存的延时队列里面，会有随着 JVM 进程死亡，丢失更新的风险，如果放在 MQ 里面会增加编码的复杂性。



- 闪电缓存

把缓存的失效时间设置的非常短，比如3-4秒，一旦失效就会再次去数据库读取最新数据到缓存，在非常高的并发下，同一时间对某个key的请求击穿到 DB。



缓存击穿：

在极高的并发情况下，直接删除缓存是有风险的。

- 读操作互斥：使用锁或者分布式锁来控制
- 更新集中：采用定时或者binlog的方式同步更新



分布式锁和非分布式锁的主要区别：

- 对于多线程来说，可能某些节点执行的非常慢，更新了就的值到Redis
- 对于分布式锁，肯定有事一个效率上的话题

集中更新：

- 通过binlog 方式，典型的如：Canal
- 设计一个服务，订阅最新的 binlog 更新信息

弱化数据库，把Redis 当做数据库使用，有定时任务定期的把 Redis 中的数据保存到数据库或者其他地方，如果是重要的业务，需要配备一个对账系统，进行扫描，以便快速发现不一致的情况。



如何正确的使用分布式锁避免缓冲击穿？